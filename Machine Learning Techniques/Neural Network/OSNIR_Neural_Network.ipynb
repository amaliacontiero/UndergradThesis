{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import OSNIR Dataset and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OSNIR dataset\n",
    "df = pd.read_csv('../Data/OSNIR_Shuffled_Data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide data into\\\n",
    "1800 values for training (0,1800-1)\\\n",
    "600 values for validation (1800,2400-1)\\\n",
    "600 values for testing (2400,3000-1)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df)\n",
    "# input x aka Ns, Pch, L, B, GB, Nch values\n",
    "x_train = data[0:1800-1, 1:7]\n",
    "x_valid = data[1800:2400-1, 1:7]\n",
    "x_test = data[2400:3000-1, 1:7]\n",
    "\n",
    "# output y aka OSNIR values\n",
    "y_train = data[0:1800-1, 0]\n",
    "y_valid = data[1800:2400-1, 0]\n",
    "y_test = data[2400:3000-1, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Deep Neural Network Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 input layer, 2 hidden layers (32 neurons each) and 1 output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, input_shape=(6,), activation='relu'),  # first hidden layer\n",
    "    keras.layers.Dense(32, activation='relu'),  # second hidden layer\n",
    "    keras.layers.Dense(1) # output layer\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early hault of training if loss has not improved in 50 epochs in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',mode='min',patience=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimizer, Mean Square Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model, run for 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "57/57 [==============================] - 1s 5ms/step - loss: 126.6372 - val_loss: 61.6811\n",
      "Epoch 2/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 54.4770 - val_loss: 48.1968\n",
      "Epoch 3/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 43.9193 - val_loss: 40.2099\n",
      "Epoch 4/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 35.4978 - val_loss: 35.5365\n",
      "Epoch 5/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 31.9444 - val_loss: 33.5386\n",
      "Epoch 6/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 29.6130 - val_loss: 37.1080\n",
      "Epoch 7/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 27.8791 - val_loss: 31.2090\n",
      "Epoch 8/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 25.2602 - val_loss: 29.8716\n",
      "Epoch 9/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 23.7299 - val_loss: 26.2044\n",
      "Epoch 10/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 22.6318 - val_loss: 25.0484\n",
      "Epoch 11/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 20.8985 - val_loss: 24.5692\n",
      "Epoch 12/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 20.3283 - val_loss: 22.6033\n",
      "Epoch 13/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 19.0836 - val_loss: 21.9682\n",
      "Epoch 14/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 18.4791 - val_loss: 20.1671\n",
      "Epoch 15/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 16.9964 - val_loss: 19.4073\n",
      "Epoch 16/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 15.2276 - val_loss: 17.5618\n",
      "Epoch 17/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 14.3742 - val_loss: 15.9721\n",
      "Epoch 18/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 12.9978 - val_loss: 14.9718\n",
      "Epoch 19/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 11.6355 - val_loss: 13.6907\n",
      "Epoch 20/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 10.9934 - val_loss: 13.1384\n",
      "Epoch 21/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 10.0231 - val_loss: 11.6986\n",
      "Epoch 22/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 8.9263 - val_loss: 10.0734\n",
      "Epoch 23/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 7.8921 - val_loss: 9.6973\n",
      "Epoch 24/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 7.1909 - val_loss: 8.0095\n",
      "Epoch 25/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 6.3603 - val_loss: 7.4967\n",
      "Epoch 26/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 6.0414 - val_loss: 7.2810\n",
      "Epoch 27/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.3789 - val_loss: 6.5263\n",
      "Epoch 28/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 5.1915 - val_loss: 5.5760\n",
      "Epoch 29/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 4.4403 - val_loss: 5.4851\n",
      "Epoch 30/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.3656 - val_loss: 4.8344\n",
      "Epoch 31/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.0514 - val_loss: 5.3106\n",
      "Epoch 32/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.7007 - val_loss: 4.8477\n",
      "Epoch 33/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.4648 - val_loss: 3.8979\n",
      "Epoch 34/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 3.2322 - val_loss: 3.5763\n",
      "Epoch 35/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.9407 - val_loss: 3.3957\n",
      "Epoch 36/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.9471 - val_loss: 3.6226\n",
      "Epoch 37/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.7679 - val_loss: 3.5525\n",
      "Epoch 38/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.4634 - val_loss: 2.9153\n",
      "Epoch 39/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.5513 - val_loss: 2.6562\n",
      "Epoch 40/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.2929 - val_loss: 2.8470\n",
      "Epoch 41/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 2.2172 - val_loss: 2.5183\n",
      "Epoch 42/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.1442 - val_loss: 2.5220\n",
      "Epoch 43/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9229 - val_loss: 2.2873\n",
      "Epoch 44/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.9639 - val_loss: 2.1371\n",
      "Epoch 45/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.7066 - val_loss: 2.0501\n",
      "Epoch 46/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.0113 - val_loss: 1.9761\n",
      "Epoch 47/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.7762 - val_loss: 2.7196\n",
      "Epoch 48/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.7392 - val_loss: 1.7850\n",
      "Epoch 49/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.3830 - val_loss: 1.6186\n",
      "Epoch 50/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3661 - val_loss: 1.7583\n",
      "Epoch 51/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.4080 - val_loss: 2.0284\n",
      "Epoch 52/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.3226 - val_loss: 1.6407\n",
      "Epoch 53/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.2674 - val_loss: 1.3447\n",
      "Epoch 54/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.2469 - val_loss: 1.4991\n",
      "Epoch 55/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1014 - val_loss: 1.2712\n",
      "Epoch 56/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1894 - val_loss: 1.3194\n",
      "Epoch 57/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.0749 - val_loss: 1.3693\n",
      "Epoch 58/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.0187 - val_loss: 1.2815\n",
      "Epoch 59/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 1.3233\n",
      "Epoch 60/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.0107 - val_loss: 1.1058\n",
      "Epoch 61/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8789 - val_loss: 1.1291\n",
      "Epoch 62/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.8908 - val_loss: 1.2736\n",
      "Epoch 63/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1134 - val_loss: 1.0743\n",
      "Epoch 64/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8823 - val_loss: 1.0309\n",
      "Epoch 65/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.8566 - val_loss: 1.0203\n",
      "Epoch 66/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.0202 - val_loss: 1.0766\n",
      "Epoch 67/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.8068 - val_loss: 0.9098\n",
      "Epoch 68/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8089 - val_loss: 1.1615\n",
      "Epoch 69/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8779 - val_loss: 1.1127\n",
      "Epoch 70/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7502 - val_loss: 1.0449\n",
      "Epoch 71/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.8076 - val_loss: 1.0298\n",
      "Epoch 72/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6735 - val_loss: 0.8876\n",
      "Epoch 73/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7729 - val_loss: 1.0586\n",
      "Epoch 74/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7318 - val_loss: 0.8683\n",
      "Epoch 75/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6845 - val_loss: 0.8881\n",
      "Epoch 76/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.7878 - val_loss: 0.8724\n",
      "Epoch 77/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6599 - val_loss: 1.4152\n",
      "Epoch 78/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.9090 - val_loss: 1.0590\n",
      "Epoch 79/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6700 - val_loss: 0.8834\n",
      "Epoch 80/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6239 - val_loss: 0.8216\n",
      "Epoch 81/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6256 - val_loss: 1.1270\n",
      "Epoch 82/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6615 - val_loss: 0.7313\n",
      "Epoch 83/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5892 - val_loss: 0.7801\n",
      "Epoch 84/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7236 - val_loss: 0.7249\n",
      "Epoch 85/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6245 - val_loss: 0.7075\n",
      "Epoch 86/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6555 - val_loss: 0.8079\n",
      "Epoch 87/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6388 - val_loss: 1.0857\n",
      "Epoch 88/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6448 - val_loss: 0.7224\n",
      "Epoch 89/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5542 - val_loss: 1.0213\n",
      "Epoch 90/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5917 - val_loss: 0.8869\n",
      "Epoch 91/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.8808\n",
      "Epoch 92/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6593 - val_loss: 0.9012\n",
      "Epoch 93/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.6110 - val_loss: 0.7233\n",
      "Epoch 94/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6070 - val_loss: 0.7829\n",
      "Epoch 95/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.6010 - val_loss: 0.9743\n",
      "Epoch 96/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5532 - val_loss: 0.7234\n",
      "Epoch 97/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 1.0531\n",
      "Epoch 98/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.6127 - val_loss: 0.9918\n",
      "Epoch 99/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5522 - val_loss: 0.7648\n",
      "Epoch 100/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5140 - val_loss: 0.6043\n",
      "Epoch 101/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4862 - val_loss: 0.6197\n",
      "Epoch 102/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5406 - val_loss: 0.6578\n",
      "Epoch 103/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5177 - val_loss: 0.8621\n",
      "Epoch 104/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4722 - val_loss: 0.9058\n",
      "Epoch 105/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4907 - val_loss: 0.6354\n",
      "Epoch 106/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4559 - val_loss: 0.7962\n",
      "Epoch 107/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4611 - val_loss: 0.7081\n",
      "Epoch 108/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.7349\n",
      "Epoch 109/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4832 - val_loss: 0.5889\n",
      "Epoch 110/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 1.2747\n",
      "Epoch 111/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4727 - val_loss: 0.5862\n",
      "Epoch 112/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4842 - val_loss: 0.6399\n",
      "Epoch 113/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4107 - val_loss: 0.8156\n",
      "Epoch 114/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5110 - val_loss: 0.6294\n",
      "Epoch 115/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5102 - val_loss: 0.6861\n",
      "Epoch 116/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5028 - val_loss: 0.6038\n",
      "Epoch 117/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4831 - val_loss: 0.6899\n",
      "Epoch 118/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4979 - val_loss: 0.8656\n",
      "Epoch 119/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.5171 - val_loss: 0.7011\n",
      "Epoch 120/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5723 - val_loss: 0.6296\n",
      "Epoch 121/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4817 - val_loss: 0.6319\n",
      "Epoch 122/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4192 - val_loss: 0.6715\n",
      "Epoch 123/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.6721\n",
      "Epoch 124/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4950 - val_loss: 0.7445\n",
      "Epoch 125/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4856 - val_loss: 0.5588\n",
      "Epoch 126/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.5776\n",
      "Epoch 127/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4234 - val_loss: 0.6422\n",
      "Epoch 128/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5411 - val_loss: 0.6859\n",
      "Epoch 129/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.7722\n",
      "Epoch 130/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4736 - val_loss: 0.6011\n",
      "Epoch 131/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3894 - val_loss: 0.5302\n",
      "Epoch 132/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3949 - val_loss: 0.7082\n",
      "Epoch 133/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4266 - val_loss: 1.0939\n",
      "Epoch 134/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4008 - val_loss: 0.5899\n",
      "Epoch 135/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3651 - val_loss: 0.4999\n",
      "Epoch 136/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3668 - val_loss: 0.5976\n",
      "Epoch 137/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4513 - val_loss: 0.5189\n",
      "Epoch 138/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3911 - val_loss: 0.6208\n",
      "Epoch 139/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4031 - val_loss: 0.5295\n",
      "Epoch 140/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.5691\n",
      "Epoch 141/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4458 - val_loss: 0.5468\n",
      "Epoch 142/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3552 - val_loss: 0.4835\n",
      "Epoch 143/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3541 - val_loss: 0.6924\n",
      "Epoch 144/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4361 - val_loss: 0.5523\n",
      "Epoch 145/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3525 - val_loss: 0.5050\n",
      "Epoch 146/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3442 - val_loss: 0.4632\n",
      "Epoch 147/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3315 - val_loss: 0.5159\n",
      "Epoch 148/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4072 - val_loss: 0.6033\n",
      "Epoch 149/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3908 - val_loss: 0.6847\n",
      "Epoch 150/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3480 - val_loss: 0.4440\n",
      "Epoch 151/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4029 - val_loss: 0.4867\n",
      "Epoch 152/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.6015\n",
      "Epoch 153/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.5105\n",
      "Epoch 154/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.4877\n",
      "Epoch 155/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3443 - val_loss: 0.5255\n",
      "Epoch 156/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3384 - val_loss: 0.4524\n",
      "Epoch 157/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3417 - val_loss: 0.6798\n",
      "Epoch 158/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3495 - val_loss: 0.5654\n",
      "Epoch 159/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3339 - val_loss: 0.4843\n",
      "Epoch 160/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2841 - val_loss: 0.4494\n",
      "Epoch 161/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3101 - val_loss: 0.5111\n",
      "Epoch 162/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3629 - val_loss: 1.0587\n",
      "Epoch 163/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3383 - val_loss: 0.4688\n",
      "Epoch 164/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3218 - val_loss: 0.5086\n",
      "Epoch 165/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4090 - val_loss: 0.3842\n",
      "Epoch 166/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3181 - val_loss: 0.4721\n",
      "Epoch 167/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4891 - val_loss: 0.5840\n",
      "Epoch 168/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3257 - val_loss: 0.4042\n",
      "Epoch 169/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2790 - val_loss: 0.6671\n",
      "Epoch 170/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2814 - val_loss: 0.4180\n",
      "Epoch 171/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2832 - val_loss: 0.5157\n",
      "Epoch 172/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2783 - val_loss: 0.4452\n",
      "Epoch 173/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2789 - val_loss: 0.3819\n",
      "Epoch 174/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3044 - val_loss: 0.4463\n",
      "Epoch 175/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3000 - val_loss: 0.4225\n",
      "Epoch 176/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2966 - val_loss: 0.4295\n",
      "Epoch 177/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2989 - val_loss: 0.4247\n",
      "Epoch 178/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3042 - val_loss: 0.4395\n",
      "Epoch 179/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2682 - val_loss: 0.4676\n",
      "Epoch 180/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3212 - val_loss: 0.5318\n",
      "Epoch 181/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4004 - val_loss: 0.9429\n",
      "Epoch 182/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4302 - val_loss: 0.7140\n",
      "Epoch 183/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4047 - val_loss: 0.4872\n",
      "Epoch 184/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2838 - val_loss: 0.6440\n",
      "Epoch 185/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2496 - val_loss: 0.3458\n",
      "Epoch 186/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2599 - val_loss: 0.3675\n",
      "Epoch 187/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3086 - val_loss: 0.4429\n",
      "Epoch 188/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3149 - val_loss: 0.6592\n",
      "Epoch 189/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3692 - val_loss: 0.3846\n",
      "Epoch 190/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2477 - val_loss: 0.6238\n",
      "Epoch 191/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3352 - val_loss: 0.4395\n",
      "Epoch 192/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2428 - val_loss: 0.3836\n",
      "Epoch 193/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.3851\n",
      "Epoch 194/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3165 - val_loss: 0.3954\n",
      "Epoch 195/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2338 - val_loss: 0.4290\n",
      "Epoch 196/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2469 - val_loss: 0.4420\n",
      "Epoch 197/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2457 - val_loss: 0.4509\n",
      "Epoch 198/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4429 - val_loss: 0.6076\n",
      "Epoch 199/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2772 - val_loss: 0.3688\n",
      "Epoch 200/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2869 - val_loss: 0.3927\n",
      "Epoch 201/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2428 - val_loss: 0.5864\n",
      "Epoch 202/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3092 - val_loss: 0.4878\n",
      "Epoch 203/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2332 - val_loss: 0.4967\n",
      "Epoch 204/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2450 - val_loss: 0.4027\n",
      "Epoch 205/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2297 - val_loss: 0.3262\n",
      "Epoch 206/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2841 - val_loss: 0.3372\n",
      "Epoch 207/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2874 - val_loss: 0.3361\n",
      "Epoch 208/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2539 - val_loss: 0.6560\n",
      "Epoch 209/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3023 - val_loss: 0.3551\n",
      "Epoch 210/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2242 - val_loss: 0.6157\n",
      "Epoch 211/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5021 - val_loss: 0.5010\n",
      "Epoch 212/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3219 - val_loss: 0.3143\n",
      "Epoch 213/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2138 - val_loss: 0.3046\n",
      "Epoch 214/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2035 - val_loss: 0.3825\n",
      "Epoch 215/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2419 - val_loss: 0.3707\n",
      "Epoch 216/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2732 - val_loss: 0.4110\n",
      "Epoch 217/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2180 - val_loss: 0.3176\n",
      "Epoch 218/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.7860\n",
      "Epoch 219/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3452 - val_loss: 0.3149\n",
      "Epoch 220/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2193 - val_loss: 0.3242\n",
      "Epoch 221/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2280 - val_loss: 0.3657\n",
      "Epoch 222/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2027 - val_loss: 0.3525\n",
      "Epoch 223/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3144 - val_loss: 0.3830\n",
      "Epoch 224/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2091 - val_loss: 0.3537\n",
      "Epoch 225/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2469 - val_loss: 0.3733\n",
      "Epoch 226/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2249 - val_loss: 0.3018\n",
      "Epoch 227/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1965 - val_loss: 0.2925\n",
      "Epoch 228/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2354 - val_loss: 0.2550\n",
      "Epoch 229/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2365 - val_loss: 0.3595\n",
      "Epoch 230/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3242 - val_loss: 0.3143\n",
      "Epoch 231/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3116 - val_loss: 0.3804\n",
      "Epoch 232/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1811 - val_loss: 0.2043\n",
      "Epoch 233/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2416 - val_loss: 0.5589\n",
      "Epoch 234/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1955 - val_loss: 0.2508\n",
      "Epoch 235/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2554 - val_loss: 0.3715\n",
      "Epoch 236/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1987 - val_loss: 0.2024\n",
      "Epoch 237/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.2182 - val_loss: 0.2546\n",
      "Epoch 238/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1767 - val_loss: 0.4240\n",
      "Epoch 239/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1947 - val_loss: 0.2025\n",
      "Epoch 240/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1975 - val_loss: 0.2329\n",
      "Epoch 241/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1837 - val_loss: 0.4162\n",
      "Epoch 242/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2103 - val_loss: 0.3336\n",
      "Epoch 243/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2071 - val_loss: 0.2843\n",
      "Epoch 244/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2553 - val_loss: 0.2553\n",
      "Epoch 245/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1759 - val_loss: 0.3135\n",
      "Epoch 246/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1616 - val_loss: 0.2195\n",
      "Epoch 247/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1735 - val_loss: 0.1944\n",
      "Epoch 248/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1972 - val_loss: 0.2766\n",
      "Epoch 249/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1867 - val_loss: 0.2128\n",
      "Epoch 250/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2089 - val_loss: 0.2144\n",
      "Epoch 251/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1769 - val_loss: 0.1803\n",
      "Epoch 252/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1670 - val_loss: 0.4007\n",
      "Epoch 253/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2107 - val_loss: 0.2051\n",
      "Epoch 254/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1817 - val_loss: 0.2008\n",
      "Epoch 255/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1690 - val_loss: 0.2212\n",
      "Epoch 256/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1575 - val_loss: 0.2625\n",
      "Epoch 257/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1760 - val_loss: 0.2810\n",
      "Epoch 258/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1613 - val_loss: 0.1887\n",
      "Epoch 259/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2290 - val_loss: 0.1942\n",
      "Epoch 260/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2315 - val_loss: 0.4796\n",
      "Epoch 261/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2414 - val_loss: 0.2435\n",
      "Epoch 262/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2010 - val_loss: 0.2600\n",
      "Epoch 263/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1800 - val_loss: 0.3570\n",
      "Epoch 264/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1881 - val_loss: 0.3034\n",
      "Epoch 265/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1967 - val_loss: 0.2227\n",
      "Epoch 266/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1603 - val_loss: 0.2554\n",
      "Epoch 267/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1643 - val_loss: 0.2719\n",
      "Epoch 268/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1973 - val_loss: 0.2151\n",
      "Epoch 269/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1950 - val_loss: 0.2386\n",
      "Epoch 270/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.2600\n",
      "Epoch 271/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1961 - val_loss: 0.2578\n",
      "Epoch 272/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1663 - val_loss: 0.2640\n",
      "Epoch 273/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1669 - val_loss: 0.3229\n",
      "Epoch 274/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1991 - val_loss: 0.2366\n",
      "Epoch 275/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2127 - val_loss: 0.3003\n",
      "Epoch 276/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2105 - val_loss: 0.2219\n",
      "Epoch 277/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1359 - val_loss: 0.2206\n",
      "Epoch 278/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1750 - val_loss: 0.2055\n",
      "Epoch 279/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1672 - val_loss: 0.9578\n",
      "Epoch 280/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3260 - val_loss: 0.2478\n",
      "Epoch 281/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1835 - val_loss: 0.1916\n",
      "Epoch 282/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1727 - val_loss: 0.1753\n",
      "Epoch 283/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1898 - val_loss: 0.2869\n",
      "Epoch 284/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1703 - val_loss: 0.4317\n",
      "Epoch 285/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2192 - val_loss: 0.2029\n",
      "Epoch 286/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1449 - val_loss: 0.1900\n",
      "Epoch 287/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1300 - val_loss: 0.1613\n",
      "Epoch 288/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1830 - val_loss: 0.2243\n",
      "Epoch 289/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.5736\n",
      "Epoch 290/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1925 - val_loss: 0.1941\n",
      "Epoch 291/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1703 - val_loss: 0.2310\n",
      "Epoch 292/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2042 - val_loss: 0.3312\n",
      "Epoch 293/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2081 - val_loss: 0.1881\n",
      "Epoch 294/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1885 - val_loss: 0.2376\n",
      "Epoch 295/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1910 - val_loss: 0.1671\n",
      "Epoch 296/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1904 - val_loss: 0.3055\n",
      "Epoch 297/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2047 - val_loss: 0.1668\n",
      "Epoch 298/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1862 - val_loss: 0.1935\n",
      "Epoch 299/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1399 - val_loss: 0.2151\n",
      "Epoch 300/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1911 - val_loss: 0.1925\n",
      "Epoch 301/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1715 - val_loss: 0.2564\n",
      "Epoch 302/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1421 - val_loss: 0.3206\n",
      "Epoch 303/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1678 - val_loss: 0.1918\n",
      "Epoch 304/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1592 - val_loss: 0.1547\n",
      "Epoch 305/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1420 - val_loss: 0.2224\n",
      "Epoch 306/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1534 - val_loss: 0.5105\n",
      "Epoch 307/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2874 - val_loss: 0.2248\n",
      "Epoch 308/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1325 - val_loss: 0.2821\n",
      "Epoch 309/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2175 - val_loss: 0.2685\n",
      "Epoch 310/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2074 - val_loss: 0.2677\n",
      "Epoch 311/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1662 - val_loss: 0.2555\n",
      "Epoch 312/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1918 - val_loss: 0.2334\n",
      "Epoch 313/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2078 - val_loss: 0.2617\n",
      "Epoch 314/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1480 - val_loss: 0.2140\n",
      "Epoch 315/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1790 - val_loss: 0.2289\n",
      "Epoch 316/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2104 - val_loss: 0.1670\n",
      "Epoch 317/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1417 - val_loss: 0.1580\n",
      "Epoch 318/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1749 - val_loss: 0.3795\n",
      "Epoch 319/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1514 - val_loss: 0.3848\n",
      "Epoch 320/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1809 - val_loss: 0.1593\n",
      "Epoch 321/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1405 - val_loss: 0.3372\n",
      "Epoch 322/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2050 - val_loss: 0.2928\n",
      "Epoch 323/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1709 - val_loss: 0.1698\n",
      "Epoch 324/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1315 - val_loss: 0.1776\n",
      "Epoch 325/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1206 - val_loss: 0.1570\n",
      "Epoch 326/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1260 - val_loss: 0.2849\n",
      "Epoch 327/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1453 - val_loss: 0.3331\n",
      "Epoch 328/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1591 - val_loss: 0.1643\n",
      "Epoch 329/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1514 - val_loss: 0.1779\n",
      "Epoch 330/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1407 - val_loss: 0.1459\n",
      "Epoch 331/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1350 - val_loss: 0.3046\n",
      "Epoch 332/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1708 - val_loss: 0.1902\n",
      "Epoch 333/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1443 - val_loss: 0.1662\n",
      "Epoch 334/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1321 - val_loss: 0.2157\n",
      "Epoch 335/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1364 - val_loss: 0.1855\n",
      "Epoch 336/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1783 - val_loss: 0.2422\n",
      "Epoch 337/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1597 - val_loss: 0.3025\n",
      "Epoch 338/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1343 - val_loss: 0.1985\n",
      "Epoch 339/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1723 - val_loss: 0.1712\n",
      "Epoch 340/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1232 - val_loss: 0.2003\n",
      "Epoch 341/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3090 - val_loss: 0.2223\n",
      "Epoch 342/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1512 - val_loss: 0.1734\n",
      "Epoch 343/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1184 - val_loss: 0.1556\n",
      "Epoch 344/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1463 - val_loss: 0.1460\n",
      "Epoch 345/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2095 - val_loss: 0.1645\n",
      "Epoch 346/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1309 - val_loss: 0.1770\n",
      "Epoch 347/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1252 - val_loss: 0.2601\n",
      "Epoch 348/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2218 - val_loss: 0.3042\n",
      "Epoch 349/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1313 - val_loss: 0.1487\n",
      "Epoch 350/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1143 - val_loss: 0.1329\n",
      "Epoch 351/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1362\n",
      "Epoch 352/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1543 - val_loss: 0.1407\n",
      "Epoch 353/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1143 - val_loss: 0.2203\n",
      "Epoch 354/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1355 - val_loss: 0.1552\n",
      "Epoch 355/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.1477\n",
      "Epoch 356/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1010 - val_loss: 0.2009\n",
      "Epoch 357/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1257 - val_loss: 0.2105\n",
      "Epoch 358/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2017 - val_loss: 0.2582\n",
      "Epoch 359/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2157 - val_loss: 0.2976\n",
      "Epoch 360/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1883 - val_loss: 0.1901\n",
      "Epoch 361/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1164 - val_loss: 0.1596\n",
      "Epoch 362/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1354 - val_loss: 0.1770\n",
      "Epoch 363/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1435 - val_loss: 0.2529\n",
      "Epoch 364/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1308 - val_loss: 0.1929\n",
      "Epoch 365/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1246 - val_loss: 0.1582\n",
      "Epoch 366/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1260 - val_loss: 0.2304\n",
      "Epoch 367/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1970 - val_loss: 0.2243\n",
      "Epoch 368/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1171 - val_loss: 0.1448\n",
      "Epoch 369/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1317 - val_loss: 0.3145\n",
      "Epoch 370/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1583 - val_loss: 0.2113\n",
      "Epoch 371/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1272 - val_loss: 0.1916\n",
      "Epoch 372/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1341 - val_loss: 0.1531\n",
      "Epoch 373/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1637 - val_loss: 0.1932\n",
      "Epoch 374/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1198 - val_loss: 0.1658\n",
      "Epoch 375/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1126 - val_loss: 0.1512\n",
      "Epoch 376/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1121 - val_loss: 0.2116\n",
      "Epoch 377/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2101 - val_loss: 0.2578\n",
      "Epoch 378/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1184 - val_loss: 0.1748\n",
      "Epoch 379/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1304 - val_loss: 0.1838\n",
      "Epoch 380/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1483 - val_loss: 0.1620\n",
      "Epoch 381/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1361 - val_loss: 0.2777\n",
      "Epoch 382/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1636 - val_loss: 0.1851\n",
      "Epoch 383/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.1346\n",
      "Epoch 384/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1126 - val_loss: 0.1496\n",
      "Epoch 385/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1695 - val_loss: 0.1423\n",
      "Epoch 386/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1359 - val_loss: 0.1591\n",
      "Epoch 387/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1243 - val_loss: 0.1272\n",
      "Epoch 388/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1166 - val_loss: 0.1707\n",
      "Epoch 389/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1098 - val_loss: 0.2059\n",
      "Epoch 390/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1458 - val_loss: 0.1600\n",
      "Epoch 391/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1606 - val_loss: 0.2445\n",
      "Epoch 392/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1292 - val_loss: 0.1467\n",
      "Epoch 393/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1454 - val_loss: 0.1581\n",
      "Epoch 394/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1184 - val_loss: 0.1690\n",
      "Epoch 395/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1114 - val_loss: 0.2576\n",
      "Epoch 396/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1359 - val_loss: 0.1344\n",
      "Epoch 397/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1166 - val_loss: 0.2450\n",
      "Epoch 398/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.1591\n",
      "Epoch 399/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1527 - val_loss: 0.2836\n",
      "Epoch 400/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1217 - val_loss: 0.1331\n",
      "Epoch 401/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1153 - val_loss: 0.1611\n",
      "Epoch 402/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1038 - val_loss: 0.2130\n",
      "Epoch 403/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1169 - val_loss: 0.5560\n",
      "Epoch 404/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1655 - val_loss: 0.1842\n",
      "Epoch 405/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2429 - val_loss: 0.2025\n",
      "Epoch 406/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1439 - val_loss: 0.1816\n",
      "Epoch 407/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1254 - val_loss: 0.1240\n",
      "Epoch 408/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1395 - val_loss: 0.2580\n",
      "Epoch 409/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1495 - val_loss: 0.2675\n",
      "Epoch 410/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1206 - val_loss: 0.2040\n",
      "Epoch 411/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1152 - val_loss: 0.1344\n",
      "Epoch 412/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1102 - val_loss: 0.2012\n",
      "Epoch 413/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1333 - val_loss: 0.1596\n",
      "Epoch 414/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1166 - val_loss: 0.1922\n",
      "Epoch 415/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1183 - val_loss: 0.1349\n",
      "Epoch 416/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1227 - val_loss: 0.2495\n",
      "Epoch 417/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1547 - val_loss: 0.1582\n",
      "Epoch 418/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1130 - val_loss: 0.1296\n",
      "Epoch 419/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.1696\n",
      "Epoch 420/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1233 - val_loss: 0.2173\n",
      "Epoch 421/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1377 - val_loss: 0.2813\n",
      "Epoch 422/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1304 - val_loss: 0.1314\n",
      "Epoch 423/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2123 - val_loss: 0.2595\n",
      "Epoch 424/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1505 - val_loss: 0.2110\n",
      "Epoch 425/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1022 - val_loss: 0.1712\n",
      "Epoch 426/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1134 - val_loss: 0.2457\n",
      "Epoch 427/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1343 - val_loss: 0.2321\n",
      "Epoch 428/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1081 - val_loss: 0.1606\n",
      "Epoch 429/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1478 - val_loss: 0.1794\n",
      "Epoch 430/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1579 - val_loss: 0.1733\n",
      "Epoch 431/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1212 - val_loss: 0.2159\n",
      "Epoch 432/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1201 - val_loss: 0.1860\n",
      "Epoch 433/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1136 - val_loss: 0.2905\n",
      "Epoch 434/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1810 - val_loss: 0.1652\n",
      "Epoch 435/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1319 - val_loss: 0.2732\n",
      "Epoch 436/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1175 - val_loss: 0.1389\n",
      "Epoch 437/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1381 - val_loss: 0.2806\n",
      "Epoch 438/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1430 - val_loss: 0.3996\n",
      "Epoch 439/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1892 - val_loss: 0.1463\n",
      "Epoch 440/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1092 - val_loss: 0.1507\n",
      "Epoch 441/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.1224\n",
      "Epoch 442/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0990 - val_loss: 0.1509\n",
      "Epoch 443/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1102 - val_loss: 0.1530\n",
      "Epoch 444/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0902 - val_loss: 0.3040\n",
      "Epoch 445/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1403 - val_loss: 0.1733\n",
      "Epoch 446/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1134 - val_loss: 0.1776\n",
      "Epoch 447/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1196 - val_loss: 0.1419\n",
      "Epoch 448/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1087 - val_loss: 0.3290\n",
      "Epoch 449/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1553\n",
      "Epoch 450/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1026 - val_loss: 0.1861\n",
      "Epoch 451/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1345 - val_loss: 0.2255\n",
      "Epoch 452/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1125 - val_loss: 0.1260\n",
      "Epoch 453/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0979 - val_loss: 0.1128\n",
      "Epoch 454/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.1977\n",
      "Epoch 455/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1093 - val_loss: 0.2322\n",
      "Epoch 456/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2051 - val_loss: 0.1664\n",
      "Epoch 457/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0971 - val_loss: 0.1414\n",
      "Epoch 458/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1320 - val_loss: 0.1394\n",
      "Epoch 459/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0866 - val_loss: 0.2304\n",
      "Epoch 460/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1279 - val_loss: 0.2637\n",
      "Epoch 461/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1402 - val_loss: 0.1239\n",
      "Epoch 462/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1112 - val_loss: 0.2469\n",
      "Epoch 463/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1577 - val_loss: 0.1341\n",
      "Epoch 464/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1132 - val_loss: 0.2516\n",
      "Epoch 465/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.2613\n",
      "Epoch 466/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1287 - val_loss: 0.1867\n",
      "Epoch 467/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1071 - val_loss: 0.1312\n",
      "Epoch 468/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1154 - val_loss: 0.1404\n",
      "Epoch 469/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0886 - val_loss: 0.1849\n",
      "Epoch 470/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1055 - val_loss: 0.1512\n",
      "Epoch 471/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1054 - val_loss: 0.2363\n",
      "Epoch 472/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1379 - val_loss: 0.1709\n",
      "Epoch 473/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1024 - val_loss: 0.1273\n",
      "Epoch 474/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1226 - val_loss: 0.2023\n",
      "Epoch 475/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2120 - val_loss: 0.1598\n",
      "Epoch 476/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1079 - val_loss: 0.2110\n",
      "Epoch 477/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1044 - val_loss: 0.1616\n",
      "Epoch 478/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1289 - val_loss: 0.2049\n",
      "Epoch 479/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0990 - val_loss: 0.3464\n",
      "Epoch 480/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1789 - val_loss: 0.1538\n",
      "Epoch 481/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0957 - val_loss: 0.1248\n",
      "Epoch 482/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1007 - val_loss: 0.1817\n",
      "Epoch 483/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1535 - val_loss: 0.4097\n",
      "Epoch 484/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1610 - val_loss: 0.1576\n",
      "Epoch 485/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.0858 - val_loss: 0.1268\n",
      "Epoch 486/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.1660\n",
      "Epoch 487/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.1269\n",
      "Epoch 488/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0869 - val_loss: 0.1559\n",
      "Epoch 489/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1008 - val_loss: 0.1116\n",
      "Epoch 490/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.0922 - val_loss: 0.1204\n",
      "Epoch 491/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1053 - val_loss: 0.2163\n",
      "Epoch 492/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1241 - val_loss: 0.1430\n",
      "Epoch 493/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1013 - val_loss: 0.1453\n",
      "Epoch 494/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1014 - val_loss: 0.2053\n",
      "Epoch 495/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1011 - val_loss: 0.1474\n",
      "Epoch 496/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1226 - val_loss: 0.4306\n",
      "Epoch 497/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1060 - val_loss: 0.1646\n",
      "Epoch 498/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1003 - val_loss: 0.1292\n",
      "Epoch 499/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1265 - val_loss: 0.2003\n",
      "Epoch 500/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.0777 - val_loss: 0.1515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d66dedba50>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,\n",
    "          validation_data=(x_valid,y_valid),\n",
    "          epochs=500,\n",
    "          callbacks=[early_stop],\n",
    "          batch_size=32,\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSNIR_num = data[:3000-1,0]\n",
    "Input_num = data[:3000-1,1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "OSNIR_est = (model.predict(Input_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33.0, 3.0, 100.0, 50.0, 0.0, 9.0] => 9.736091 (expected 9.936834)\n",
      "[6.0, -1.0, 50.0, 25.0, 0.0, 9.0] => 23.725700 (expected 23.857060)\n",
      "[12.0, -5.0, 50.0, 25.0, 0.0, 3.0] => 22.330406 (expected 22.358241)\n",
      "[16.0, 3.0, 10.0, 25.0, 12.5, 9.0] => 17.984154 (expected 17.954984)\n",
      "[10.0, -1.0, 100.0, 25.0, 0.0, 9.0] => 15.980124 (expected 16.183496)\n",
      "[7.0, 2.0, 100.0, 25.0, 0.0, 9.0] => 15.878493 (expected 16.091254)\n",
      "[7.0, -2.0, 100.0, 25.0, 0.0, 3.0] => 17.324184 (expected 17.885832)\n",
      "[13.0, 3.0, 100.0, 25.0, 12.5, 9.0] => 13.293305 (expected 13.479461)\n",
      "[15.0, -6.0, 5.0, 25.0, 0.0, 9.0] => 29.249689 (expected 29.028905)\n",
      "[14.0, -1.0, 50.0, 25.0, 0.0, 9.0] => 19.394131 (expected 19.840868)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%s => %f (expected %f)' % (Input_num[i].tolist(), OSNIR_est[i], OSNIR_num[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mism = np.zeros(3000-1)\n",
    "for i in range(3000-1):\n",
    "    Mism[i] = OSNIR_num[i] - OSNIR_est[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"Actual OSNIR (dB)\" : OSNIR_num.tolist(), \"Predicted OSNIR (dB)\" : OSNIR_est.tolist(), \"Difference (dB)\" : Mism.tolist()})\n",
    "pred_df.to_csv(\"OSNIR_Prediction_DNN.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00066689, 0.        , 0.00033344,\n",
       "        0.00100033, 0.00700233, 0.033011  , 0.10136712, 0.20973658,\n",
       "        0.24708236, 0.22207402, 0.12470824, 0.04234745, 0.00533511,\n",
       "        0.00033344, 0.00066689, 0.00066689, 0.00033344, 0.00166722,\n",
       "        0.00033344, 0.        , 0.00033344, 0.00066689, 0.        ,\n",
       "        0.        , 0.00033344, 0.        , 0.        , 0.        ]),\n",
       " array([-4. , -3.8, -3.6, -3.4, -3.2, -3. , -2.8, -2.6, -2.4, -2.2, -2. ,\n",
       "        -1.8, -1.6, -1.4, -1.2, -1. , -0.8, -0.6, -0.4, -0.2,  0. ,  0.2,\n",
       "         0.4,  0.6,  0.8,  1. ,  1.2,  1.4,  1.6,  1.8,  2. ,  2.2,  2.4,\n",
       "         2.6,  2.8,  3. ,  3.2,  3.4,  3.6,  3.8,  4. ]),\n",
       " <BarContainer object of 40 artists>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Neural Network OSNIR Mismatch')\n",
    "plt.xlabel('Mismatch (dB)')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.ylim(0, 0.3)\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.hist(Mism,\n",
    "         range=(-4,4),\n",
    "         rwidth=0.9,\n",
    "         bins=40,\n",
    "         weights=np.ones(len(Mism))/len(Mism)\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd7dbc09f62c6934dc245b76251cec5fd949cd1cb8bcb775af9208cac5a10da4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
