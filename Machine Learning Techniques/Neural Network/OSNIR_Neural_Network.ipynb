{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network (DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import OSNIR Dataset and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OSNIR dataset\n",
    "df = pd.read_csv('../Data/OSNIR_values_extendedv3_new datasetbcsv.csv')\n",
    "# shuffling rows of OSNIR dataframe and reset indexes\n",
    "df = df.sample(frac=1)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide data into\\\n",
    "1800 values for training (0,1800-1)\\\n",
    "600 values for validation (1800,2400-1)\\\n",
    "600 values for testing (2400,3000-1)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df)\n",
    "# input x aka Ns, Pch, L, B, GB, Nch values\n",
    "x_train = data[0:1800-1, 1:7]\n",
    "x_valid = data[1800:2400-1, 1:7]\n",
    "x_test = data[2400:3000-1, 1:7]\n",
    "\n",
    "# output y aka OSNIR values\n",
    "y_train = data[0:1800-1, 0]\n",
    "y_valid = data[1800:2400-1, 0]\n",
    "y_test = data[2400:3000-1, 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Deep Neural Network Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 input layer, 2 hidden layers (32 neurons each) and 1 output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, input_shape=(6,), activation='relu'),  # first hidden layer\n",
    "    keras.layers.Dense(32, activation='relu'),  # second hidden layer\n",
    "    keras.layers.Dense(1) # output layer\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early hault of training if loss has not improved in 50 epochs in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',mode='min',patience=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimizer, Mean Square Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model, run for 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "57/57 [==============================] - 1s 4ms/step - loss: 248.4097 - val_loss: 86.1414\n",
      "Epoch 2/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 60.0434 - val_loss: 49.0054\n",
      "Epoch 3/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 44.4960 - val_loss: 42.7896\n",
      "Epoch 4/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 39.0590 - val_loss: 37.3546\n",
      "Epoch 5/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 34.6546 - val_loss: 33.1769\n",
      "Epoch 6/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 31.0280 - val_loss: 30.9620\n",
      "Epoch 7/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 28.4518 - val_loss: 28.7117\n",
      "Epoch 8/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 27.1028 - val_loss: 27.5664\n",
      "Epoch 9/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 25.5665 - val_loss: 26.4356\n",
      "Epoch 10/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 24.7738 - val_loss: 25.6782\n",
      "Epoch 11/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 23.7191 - val_loss: 25.1421\n",
      "Epoch 12/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 22.8114 - val_loss: 23.8878\n",
      "Epoch 13/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 21.9170 - val_loss: 23.1214\n",
      "Epoch 14/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 21.3459 - val_loss: 22.6367\n",
      "Epoch 15/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 20.7587 - val_loss: 21.8401\n",
      "Epoch 16/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 19.8089 - val_loss: 20.7488\n",
      "Epoch 17/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 18.7735 - val_loss: 19.8982\n",
      "Epoch 18/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 17.8463 - val_loss: 20.3584\n",
      "Epoch 19/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 17.2270 - val_loss: 19.1006\n",
      "Epoch 20/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 16.3815 - val_loss: 18.0926\n",
      "Epoch 21/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 15.4844 - val_loss: 17.3518\n",
      "Epoch 22/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 14.9187 - val_loss: 16.3652\n",
      "Epoch 23/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 14.1757 - val_loss: 15.3489\n",
      "Epoch 24/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 13.3353 - val_loss: 14.5823\n",
      "Epoch 25/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 12.6937 - val_loss: 13.9140\n",
      "Epoch 26/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 12.0922 - val_loss: 13.6121\n",
      "Epoch 27/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 11.3295 - val_loss: 12.2532\n",
      "Epoch 28/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 10.5713 - val_loss: 11.7485\n",
      "Epoch 29/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9.9751 - val_loss: 10.9845\n",
      "Epoch 30/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 9.6670 - val_loss: 10.4398\n",
      "Epoch 31/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 9.1902 - val_loss: 9.9522\n",
      "Epoch 32/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 8.4113 - val_loss: 9.1341\n",
      "Epoch 33/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 7.9730 - val_loss: 8.9995\n",
      "Epoch 34/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 7.4568 - val_loss: 7.9384\n",
      "Epoch 35/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 7.0710 - val_loss: 7.6234\n",
      "Epoch 36/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 6.8233 - val_loss: 7.3176\n",
      "Epoch 37/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 6.5411 - val_loss: 6.5900\n",
      "Epoch 38/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 6.1796 - val_loss: 6.4498\n",
      "Epoch 39/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.8327 - val_loss: 5.9653\n",
      "Epoch 40/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 5.6595 - val_loss: 6.0093\n",
      "Epoch 41/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.3733 - val_loss: 5.5568\n",
      "Epoch 42/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.0268 - val_loss: 6.1525\n",
      "Epoch 43/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 5.0032 - val_loss: 5.5972\n",
      "Epoch 44/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 4.9264 - val_loss: 4.9545\n",
      "Epoch 45/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 4.3533 - val_loss: 4.9265\n",
      "Epoch 46/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 4.3856 - val_loss: 4.6628\n",
      "Epoch 47/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.9670 - val_loss: 4.2611\n",
      "Epoch 48/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.8045 - val_loss: 4.3953\n",
      "Epoch 49/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.7682 - val_loss: 3.9336\n",
      "Epoch 50/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.5158 - val_loss: 3.3122\n",
      "Epoch 51/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 3.3283 - val_loss: 3.1572\n",
      "Epoch 52/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.2993 - val_loss: 3.3375\n",
      "Epoch 53/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 3.0228 - val_loss: 3.0488\n",
      "Epoch 54/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.9691 - val_loss: 3.2486\n",
      "Epoch 55/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.9023 - val_loss: 2.9305\n",
      "Epoch 56/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.6812 - val_loss: 2.5567\n",
      "Epoch 57/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 2.5293 - val_loss: 2.6357\n",
      "Epoch 58/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 2.5458 - val_loss: 2.6729\n",
      "Epoch 59/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.4212 - val_loss: 2.3041\n",
      "Epoch 60/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.2874 - val_loss: 2.1785\n",
      "Epoch 61/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.1870 - val_loss: 3.0497\n",
      "Epoch 62/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.1521 - val_loss: 2.0693\n",
      "Epoch 63/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 2.0812 - val_loss: 1.8478\n",
      "Epoch 64/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.9714 - val_loss: 1.7757\n",
      "Epoch 65/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.8245 - val_loss: 2.0601\n",
      "Epoch 66/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.7938 - val_loss: 1.9557\n",
      "Epoch 67/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.6618 - val_loss: 1.7544\n",
      "Epoch 68/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.6032 - val_loss: 2.5684\n",
      "Epoch 69/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 1.5346 - val_loss: 1.6635\n",
      "Epoch 70/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.5017 - val_loss: 1.4309\n",
      "Epoch 71/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.4538 - val_loss: 1.5472\n",
      "Epoch 72/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.6834 - val_loss: 1.7134\n",
      "Epoch 73/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.4517 - val_loss: 1.5957\n",
      "Epoch 74/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.4179 - val_loss: 1.1819\n",
      "Epoch 75/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 1.1411 - val_loss: 1.2150\n",
      "Epoch 76/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.1192 - val_loss: 1.2148\n",
      "Epoch 77/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.2082 - val_loss: 2.9453\n",
      "Epoch 78/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 1.3782 - val_loss: 1.4547\n",
      "Epoch 79/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.0729 - val_loss: 1.0973\n",
      "Epoch 80/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.0807 - val_loss: 1.0682\n",
      "Epoch 81/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 1.0444 - val_loss: 1.0027\n",
      "Epoch 82/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.9404 - val_loss: 1.0163\n",
      "Epoch 83/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.9601 - val_loss: 0.8700\n",
      "Epoch 84/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8501 - val_loss: 1.0985\n",
      "Epoch 85/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8439 - val_loss: 0.8183\n",
      "Epoch 86/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7664 - val_loss: 0.8262\n",
      "Epoch 87/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8256 - val_loss: 1.0484\n",
      "Epoch 88/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8717 - val_loss: 0.9496\n",
      "Epoch 89/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.8755 - val_loss: 0.9397\n",
      "Epoch 90/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.8056 - val_loss: 0.8688\n",
      "Epoch 91/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.7180 - val_loss: 0.7196\n",
      "Epoch 92/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6764 - val_loss: 0.7099\n",
      "Epoch 93/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6204 - val_loss: 0.7017\n",
      "Epoch 94/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5937 - val_loss: 0.8447\n",
      "Epoch 95/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.6171 - val_loss: 0.7181\n",
      "Epoch 96/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.5693 - val_loss: 0.6741\n",
      "Epoch 97/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5734 - val_loss: 0.8009\n",
      "Epoch 98/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5240 - val_loss: 0.5940\n",
      "Epoch 99/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5192 - val_loss: 0.6023\n",
      "Epoch 100/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5156 - val_loss: 0.8412\n",
      "Epoch 101/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5376 - val_loss: 0.5326\n",
      "Epoch 102/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.5252 - val_loss: 0.6865\n",
      "Epoch 103/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4940 - val_loss: 0.7362\n",
      "Epoch 104/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5621 - val_loss: 0.5967\n",
      "Epoch 105/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 0.4781\n",
      "Epoch 106/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4582 - val_loss: 0.5051\n",
      "Epoch 107/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4242 - val_loss: 0.5384\n",
      "Epoch 108/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4242 - val_loss: 0.4936\n",
      "Epoch 109/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4166 - val_loss: 0.5020\n",
      "Epoch 110/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5786 - val_loss: 0.7785\n",
      "Epoch 111/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4723 - val_loss: 0.4732\n",
      "Epoch 112/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3997 - val_loss: 0.4667\n",
      "Epoch 113/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.4548 - val_loss: 0.4486\n",
      "Epoch 114/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3816 - val_loss: 0.4923\n",
      "Epoch 115/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4125 - val_loss: 0.6002\n",
      "Epoch 116/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3682 - val_loss: 0.5040\n",
      "Epoch 117/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3267 - val_loss: 0.4427\n",
      "Epoch 118/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3497 - val_loss: 0.5013\n",
      "Epoch 119/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3821 - val_loss: 0.4944\n",
      "Epoch 120/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3965 - val_loss: 0.5056\n",
      "Epoch 121/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3335 - val_loss: 0.4270\n",
      "Epoch 122/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3339 - val_loss: 0.5131\n",
      "Epoch 123/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3466 - val_loss: 0.4018\n",
      "Epoch 124/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.4915 - val_loss: 0.4620\n",
      "Epoch 125/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.5106 - val_loss: 0.5783\n",
      "Epoch 126/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3707 - val_loss: 0.4052\n",
      "Epoch 127/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3196 - val_loss: 0.3505\n",
      "Epoch 128/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3118 - val_loss: 0.5114\n",
      "Epoch 129/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.4609\n",
      "Epoch 130/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3420 - val_loss: 0.4783\n",
      "Epoch 131/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3468 - val_loss: 0.4812\n",
      "Epoch 132/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3260 - val_loss: 0.3779\n",
      "Epoch 133/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2704 - val_loss: 0.4209\n",
      "Epoch 134/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3206 - val_loss: 0.3404\n",
      "Epoch 135/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3204 - val_loss: 0.6344\n",
      "Epoch 136/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3031 - val_loss: 0.5054\n",
      "Epoch 137/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2709 - val_loss: 0.3735\n",
      "Epoch 138/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2707 - val_loss: 0.3045\n",
      "Epoch 139/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2645 - val_loss: 0.3436\n",
      "Epoch 140/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2724 - val_loss: 0.3556\n",
      "Epoch 141/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2705 - val_loss: 0.3181\n",
      "Epoch 142/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2428 - val_loss: 0.3087\n",
      "Epoch 143/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3133 - val_loss: 0.3258\n",
      "Epoch 144/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2538 - val_loss: 0.3299\n",
      "Epoch 145/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2244 - val_loss: 0.2968\n",
      "Epoch 146/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2532 - val_loss: 0.2878\n",
      "Epoch 147/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2505 - val_loss: 0.2925\n",
      "Epoch 148/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2403 - val_loss: 0.2982\n",
      "Epoch 149/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2629 - val_loss: 0.3412\n",
      "Epoch 150/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2423 - val_loss: 0.4033\n",
      "Epoch 151/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2374 - val_loss: 0.3046\n",
      "Epoch 152/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2357 - val_loss: 0.2721\n",
      "Epoch 153/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2300 - val_loss: 0.2718\n",
      "Epoch 154/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2113 - val_loss: 0.3134\n",
      "Epoch 155/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2111 - val_loss: 0.2752\n",
      "Epoch 156/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2079 - val_loss: 0.2613\n",
      "Epoch 157/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1955 - val_loss: 0.3109\n",
      "Epoch 158/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1991 - val_loss: 0.2613\n",
      "Epoch 159/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2257 - val_loss: 0.3471\n",
      "Epoch 160/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2315 - val_loss: 0.3483\n",
      "Epoch 161/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2415 - val_loss: 0.4009\n",
      "Epoch 162/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2631 - val_loss: 0.3946\n",
      "Epoch 163/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2694 - val_loss: 0.3526\n",
      "Epoch 164/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2227 - val_loss: 0.2892\n",
      "Epoch 165/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1988 - val_loss: 0.4666\n",
      "Epoch 166/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2235 - val_loss: 0.2712\n",
      "Epoch 167/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2484 - val_loss: 0.2625\n",
      "Epoch 168/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1995 - val_loss: 0.2590\n",
      "Epoch 169/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2425 - val_loss: 0.4227\n",
      "Epoch 170/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1950 - val_loss: 0.2269\n",
      "Epoch 171/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1931 - val_loss: 0.2464\n",
      "Epoch 172/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1976 - val_loss: 0.2855\n",
      "Epoch 173/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.2232 - val_loss: 0.2308\n",
      "Epoch 174/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1842 - val_loss: 0.2731\n",
      "Epoch 175/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1822 - val_loss: 0.3460\n",
      "Epoch 176/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3010 - val_loss: 0.3788\n",
      "Epoch 177/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2086 - val_loss: 0.2447\n",
      "Epoch 178/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1798 - val_loss: 0.3153\n",
      "Epoch 179/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2453 - val_loss: 0.5260\n",
      "Epoch 180/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2091 - val_loss: 0.2877\n",
      "Epoch 181/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1886 - val_loss: 0.3578\n",
      "Epoch 182/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.3888 - val_loss: 0.2320\n",
      "Epoch 183/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1801 - val_loss: 0.2164\n",
      "Epoch 184/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1627 - val_loss: 0.2300\n",
      "Epoch 185/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1700 - val_loss: 0.2458\n",
      "Epoch 186/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2049 - val_loss: 0.2670\n",
      "Epoch 187/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1719 - val_loss: 0.2362\n",
      "Epoch 188/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2032 - val_loss: 0.3156\n",
      "Epoch 189/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2450 - val_loss: 0.2203\n",
      "Epoch 190/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2538 - val_loss: 0.4938\n",
      "Epoch 191/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2803 - val_loss: 0.3208\n",
      "Epoch 192/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1744 - val_loss: 0.2496\n",
      "Epoch 193/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1657 - val_loss: 0.2233\n",
      "Epoch 194/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1506 - val_loss: 0.2983\n",
      "Epoch 195/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2187 - val_loss: 0.3655\n",
      "Epoch 196/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2045 - val_loss: 0.2035\n",
      "Epoch 197/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1622 - val_loss: 0.3148\n",
      "Epoch 198/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1523 - val_loss: 0.2308\n",
      "Epoch 199/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1591 - val_loss: 0.1881\n",
      "Epoch 200/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1784 - val_loss: 0.2449\n",
      "Epoch 201/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1957 - val_loss: 0.2757\n",
      "Epoch 202/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1854 - val_loss: 0.2171\n",
      "Epoch 203/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1485 - val_loss: 0.3452\n",
      "Epoch 204/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1571 - val_loss: 0.2766\n",
      "Epoch 205/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1571 - val_loss: 0.2308\n",
      "Epoch 206/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1594 - val_loss: 0.3046\n",
      "Epoch 207/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2335 - val_loss: 0.6749\n",
      "Epoch 208/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2757 - val_loss: 0.2231\n",
      "Epoch 209/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1873 - val_loss: 0.2002\n",
      "Epoch 210/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1421 - val_loss: 0.2280\n",
      "Epoch 211/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1432 - val_loss: 0.1723\n",
      "Epoch 212/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1465 - val_loss: 0.2035\n",
      "Epoch 213/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1627 - val_loss: 0.2004\n",
      "Epoch 214/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1654 - val_loss: 0.2672\n",
      "Epoch 215/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1409 - val_loss: 0.2352\n",
      "Epoch 216/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1458 - val_loss: 0.2191\n",
      "Epoch 217/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1477 - val_loss: 0.2179\n",
      "Epoch 218/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1607 - val_loss: 0.2402\n",
      "Epoch 219/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1659 - val_loss: 0.2383\n",
      "Epoch 220/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1967 - val_loss: 0.2257\n",
      "Epoch 221/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.2877\n",
      "Epoch 222/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1745 - val_loss: 0.3463\n",
      "Epoch 223/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1600 - val_loss: 0.3621\n",
      "Epoch 224/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1920 - val_loss: 0.2133\n",
      "Epoch 225/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1576 - val_loss: 0.3066\n",
      "Epoch 226/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2949 - val_loss: 0.2454\n",
      "Epoch 227/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1914 - val_loss: 0.3652\n",
      "Epoch 228/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1770 - val_loss: 0.3803\n",
      "Epoch 229/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.2424 - val_loss: 0.2333\n",
      "Epoch 230/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1609 - val_loss: 0.3495\n",
      "Epoch 231/500\n",
      "57/57 [==============================] - 0s 2ms/step - loss: 0.1528 - val_loss: 0.5352\n",
      "Epoch 232/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2333 - val_loss: 0.2153\n",
      "Epoch 233/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1271 - val_loss: 0.2103\n",
      "Epoch 234/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1338 - val_loss: 0.2740\n",
      "Epoch 235/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1402 - val_loss: 0.2124\n",
      "Epoch 236/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1324 - val_loss: 0.2838\n",
      "Epoch 237/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1554 - val_loss: 0.2010\n",
      "Epoch 238/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1579 - val_loss: 0.2701\n",
      "Epoch 239/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1433 - val_loss: 0.2091\n",
      "Epoch 240/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1326 - val_loss: 0.2985\n",
      "Epoch 241/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1530 - val_loss: 0.2076\n",
      "Epoch 242/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1431 - val_loss: 0.3253\n",
      "Epoch 243/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1770 - val_loss: 0.2915\n",
      "Epoch 244/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1371 - val_loss: 0.1654\n",
      "Epoch 245/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1436 - val_loss: 0.2674\n",
      "Epoch 246/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1467 - val_loss: 0.1877\n",
      "Epoch 247/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1638 - val_loss: 0.3156\n",
      "Epoch 248/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2769 - val_loss: 0.1973\n",
      "Epoch 249/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1549 - val_loss: 0.2060\n",
      "Epoch 250/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1287 - val_loss: 0.2068\n",
      "Epoch 251/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1789 - val_loss: 0.3711\n",
      "Epoch 252/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2848 - val_loss: 1.1473\n",
      "Epoch 253/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2417 - val_loss: 0.2137\n",
      "Epoch 254/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1122 - val_loss: 0.2092\n",
      "Epoch 255/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1764 - val_loss: 0.1983\n",
      "Epoch 256/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1661 - val_loss: 0.1914\n",
      "Epoch 257/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1181 - val_loss: 0.2662\n",
      "Epoch 258/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1696 - val_loss: 0.2385\n",
      "Epoch 259/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1110 - val_loss: 0.3070\n",
      "Epoch 260/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1240 - val_loss: 0.3005\n",
      "Epoch 261/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1696 - val_loss: 0.1936\n",
      "Epoch 262/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2398 - val_loss: 0.4912\n",
      "Epoch 263/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.3107 - val_loss: 0.3098\n",
      "Epoch 264/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1662 - val_loss: 0.1933\n",
      "Epoch 265/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1185 - val_loss: 0.2350\n",
      "Epoch 266/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1199 - val_loss: 0.3236\n",
      "Epoch 267/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2224 - val_loss: 0.3735\n",
      "Epoch 268/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1767 - val_loss: 0.2337\n",
      "Epoch 269/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1504 - val_loss: 0.2032\n",
      "Epoch 270/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1468 - val_loss: 0.3198\n",
      "Epoch 271/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1514 - val_loss: 0.2263\n",
      "Epoch 272/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1165 - val_loss: 0.1726\n",
      "Epoch 273/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.2196 - val_loss: 0.2336\n",
      "Epoch 274/500\n",
      "57/57 [==============================] - 0s 5ms/step - loss: 0.1314 - val_loss: 0.1884\n",
      "Epoch 275/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1438 - val_loss: 0.3116\n",
      "Epoch 276/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1687 - val_loss: 0.1843\n",
      "Epoch 277/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1131 - val_loss: 0.4193\n",
      "Epoch 278/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1464 - val_loss: 0.1784\n",
      "Epoch 279/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1231 - val_loss: 0.1883\n",
      "Epoch 280/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1192 - val_loss: 0.2358\n",
      "Epoch 281/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1318 - val_loss: 0.2016\n",
      "Epoch 282/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1622 - val_loss: 0.5182\n",
      "Epoch 283/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1647 - val_loss: 0.2360\n",
      "Epoch 284/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1357 - val_loss: 0.2595\n",
      "Epoch 285/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1360 - val_loss: 0.2418\n",
      "Epoch 286/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1419 - val_loss: 0.2187\n",
      "Epoch 287/500\n",
      "57/57 [==============================] - 0s 4ms/step - loss: 0.1316 - val_loss: 0.2013\n",
      "Epoch 288/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1756 - val_loss: 0.2672\n",
      "Epoch 289/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1261 - val_loss: 0.3417\n",
      "Epoch 290/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1679 - val_loss: 0.2101\n",
      "Epoch 291/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1316 - val_loss: 0.2312\n",
      "Epoch 292/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1063 - val_loss: 0.1827\n",
      "Epoch 293/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.2246 - val_loss: 0.3166\n",
      "Epoch 294/500\n",
      "57/57 [==============================] - 0s 3ms/step - loss: 0.1882 - val_loss: 0.2066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1858dfdde90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,\n",
    "          validation_data=(x_valid,y_valid),\n",
    "          epochs=500,\n",
    "          callbacks=[early_stop],\n",
    "          batch_size=32,\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "OSNIR_num = data[:3000-1,0]\n",
    "Input_num = data[:3000-1,1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "OSNIR_est = (model.predict(Input_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.0, -1.0, 50.0, 25.0, 0.0, 3.0] => 17.830681 (expected 17.385452)\n",
      "[44.0, 3.0, 10.0, 25.0, 25.0, 9.0] => 11.582586 (expected 12.215289)\n",
      "[20.0, 0.0, 10.0, 25.0, 0.0, 15.0] => 19.238708 (expected 19.599546)\n",
      "[25.0, 3.0, 50.0, 25.0, 12.5, 9.0] => 10.683617 (expected 11.019259)\n",
      "[9.0, -2.0, 50.0, 25.0, 0.0, 3.0] => 23.105650 (expected 23.664739)\n",
      "[12.0, -5.0, 5.0, 25.0, 0.0, 9.0] => 29.738222 (expected 29.953129)\n",
      "[37.0, -5.0, 50.0, 25.0, 0.0, 3.0] => 17.720675 (expected 17.640254)\n",
      "[8.0, 0.0, 50.0, 12.5, 0.0, 9.0] => 16.842009 (expected 17.130597)\n",
      "[37.0, 3.0, 10.0, 25.0, 25.0, 9.0] => 12.634636 (expected 13.303436)\n",
      "[12.0, 3.0, 50.0, 25.0, 12.5, 9.0] => 15.040394 (expected 15.340870)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%s => %f (expected %f)' % (Input_num[i].tolist(), OSNIR_est[i], OSNIR_num[i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mism = np.zeros(3000-1)\n",
    "for i in range(3000-1):\n",
    "    Mism[i] = OSNIR_num[i] - OSNIR_est[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"Actual OSNIR (dB)\" : OSNIR_num.tolist(), \"Predicted OSNIR (dB)\" : OSNIR_est.tolist(), \"Difference (dB)\" : Mism.tolist()})\n",
    "pred_df.to_csv(\"OSNIR_Prediction_DNN.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00033344, 0.00033344, 0.00133378, 0.00133378,\n",
       "        0.00433478, 0.01367122, 0.04568189, 0.13804602, 0.22540847,\n",
       "        0.22507503, 0.19206402, 0.08936312, 0.03267756, 0.01433811,\n",
       "        0.00966989, 0.00200067, 0.00100033, 0.00033344, 0.00033344,\n",
       "        0.00033344, 0.00033344, 0.        , 0.00033344, 0.        ,\n",
       "        0.00033344, 0.00066689, 0.00033344, 0.        , 0.        ,\n",
       "        0.        , 0.00033344, 0.        , 0.        , 0.        ]),\n",
       " array([-5. , -4.8, -4.6, -4.4, -4.2, -4. , -3.8, -3.6, -3.4, -3.2, -3. ,\n",
       "        -2.8, -2.6, -2.4, -2.2, -2. , -1.8, -1.6, -1.4, -1.2, -1. , -0.8,\n",
       "        -0.6, -0.4, -0.2,  0. ,  0.2,  0.4,  0.6,  0.8,  1. ,  1.2,  1.4,\n",
       "         1.6,  1.8,  2. ,  2.2,  2.4,  2.6,  2.8,  3. ,  3.2,  3.4,  3.6,\n",
       "         3.8,  4. ,  4.2,  4.4,  4.6,  4.8,  5. ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Neural Network OSNIR Mismatch')\n",
    "plt.xlabel('Mismatch (dB)')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.hist(Mism,\n",
    "         range=(-5,5),\n",
    "         rwidth=0.9,\n",
    "         bins=50,\n",
    "         weights=np.ones(len(Mism))/len(Mism)\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd7dbc09f62c6934dc245b76251cec5fd949cd1cb8bcb775af9208cac5a10da4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
