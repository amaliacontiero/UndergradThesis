{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import OSNIR Dataset and shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import OSNIR dataset\n",
    "df = pd.read_csv('../Data/OSNIR_values_extendedv3_new datasetbcsv.csv')\n",
    "# shuffling rows of OSNIR dataframe and reset indexes\n",
    "df = df.sample(frac=1)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview of first 5 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSNIRnumerical(dB)</th>\n",
       "      <th>Ns</th>\n",
       "      <th>Pch(dBm)</th>\n",
       "      <th>L(km)</th>\n",
       "      <th>B(GHz)</th>\n",
       "      <th>GB(GHz)</th>\n",
       "      <th>Nch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.822029</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.728774</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.215406</td>\n",
       "      <td>20</td>\n",
       "      <td>-2</td>\n",
       "      <td>10</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.377177</td>\n",
       "      <td>7</td>\n",
       "      <td>-6</td>\n",
       "      <td>50</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.853978</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>10</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OSNIRnumerical(dB)  Ns  Pch(dBm)  L(km)  B(GHz)  GB(GHz)  Nch\n",
       "0           19.822029  28         0     10    25.0      0.0    3\n",
       "1           10.728774  28         3    100    50.0      0.0    9\n",
       "2           26.215406  20        -2     10    50.0      0.0    9\n",
       "3           21.377177   7        -6     50    50.0      0.0    9\n",
       "4           28.853978  10        -3     10    50.0      0.0    9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1800 values for training (0,1800-1)\\\n",
    "600 values for validation (1800,2400-1)\\\n",
    "600 values for testing (2400,3000-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input x aka Ns, Pch, L, B, GB, Nch values\n",
    "x_train = data[0:1800-1, 1:7]\n",
    "x_valid = data[1800:2400-1, 1:7]\n",
    "x_test = data[2400:3000-1, 1:7]\n",
    "\n",
    "# output y aka OSNIR values\n",
    "y_train = data[0:1800-1, 0]\n",
    "y_valid = data[1800:2400-1, 0]\n",
    "y_test = data[2400:3000-1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28. ,   0. ,  10. ,  25. ,   0. ,   3. ],\n",
       "       [ 28. ,   3. , 100. ,  50. ,   0. ,   9. ],\n",
       "       [ 20. ,  -2. ,  10. ,  50. ,   0. ,   9. ],\n",
       "       ...,\n",
       "       [ 19. ,   3. ,  10. ,  25. ,  25. ,   9. ],\n",
       "       [ 41. ,  -3. ,  10. ,  12.5,   0. ,   9. ],\n",
       "       [ 11. ,  -5. ,  10. ,  50. ,   0. ,   9. ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Neural Network\n",
    "1 Input layer, 2 hidden layers (32 neurons each) and 1 Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(32, input_shape=(6,), activation='relu'),  # first hidden layer\n",
    "    keras.layers.Dense(32, activation='relu'),  # second hidden layer\n",
    "    keras.layers.Dense(1, activation='relu') # output layer (3)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early hault of training if loss has not improved in 50 epochs in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss',mode='min',patience=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimizer, Mean Square Error Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='mse'\n",
    "              #metrics=['accuracy']\n",
    "              )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model, run for 500 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "72/72 [==============================] - 1s 3ms/step - loss: 0.4777 - val_loss: 0.1682\n",
      "Epoch 2/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1231 - val_loss: 0.1727\n",
      "Epoch 3/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1472 - val_loss: 0.1690\n",
      "Epoch 4/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1742 - val_loss: 0.1586\n",
      "Epoch 5/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1584 - val_loss: 0.3798\n",
      "Epoch 6/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2686 - val_loss: 0.3247\n",
      "Epoch 7/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1948 - val_loss: 0.1808\n",
      "Epoch 8/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2067 - val_loss: 0.4823\n",
      "Epoch 9/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2195 - val_loss: 0.2234\n",
      "Epoch 10/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1737 - val_loss: 0.2219\n",
      "Epoch 11/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1666\n",
      "Epoch 12/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1977 - val_loss: 0.3057\n",
      "Epoch 13/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1728 - val_loss: 0.2674\n",
      "Epoch 14/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1587 - val_loss: 0.1989\n",
      "Epoch 15/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1620 - val_loss: 0.1818\n",
      "Epoch 16/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1626 - val_loss: 0.2030\n",
      "Epoch 17/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1883 - val_loss: 0.2805\n",
      "Epoch 18/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1837 - val_loss: 0.1590\n",
      "Epoch 19/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1629 - val_loss: 0.2480\n",
      "Epoch 20/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2048 - val_loss: 0.1850\n",
      "Epoch 21/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2174 - val_loss: 0.1917\n",
      "Epoch 22/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2949 - val_loss: 0.2024\n",
      "Epoch 23/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1704 - val_loss: 0.2473\n",
      "Epoch 24/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1767 - val_loss: 0.2188\n",
      "Epoch 25/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1649 - val_loss: 0.1515\n",
      "Epoch 26/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1848 - val_loss: 0.2179\n",
      "Epoch 27/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1546 - val_loss: 0.2352\n",
      "Epoch 28/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1611 - val_loss: 0.3497\n",
      "Epoch 29/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1700 - val_loss: 0.2298\n",
      "Epoch 30/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1773 - val_loss: 0.2380\n",
      "Epoch 31/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1344 - val_loss: 0.1545\n",
      "Epoch 32/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1493 - val_loss: 0.2111\n",
      "Epoch 33/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2773 - val_loss: 0.3893\n",
      "Epoch 34/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1774 - val_loss: 0.1837\n",
      "Epoch 35/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1324 - val_loss: 0.2953\n",
      "Epoch 36/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2391 - val_loss: 0.1741\n",
      "Epoch 37/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2105 - val_loss: 0.3596\n",
      "Epoch 38/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1894 - val_loss: 0.2743\n",
      "Epoch 39/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2086 - val_loss: 0.2822\n",
      "Epoch 40/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2089 - val_loss: 0.1425\n",
      "Epoch 41/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1411 - val_loss: 0.1551\n",
      "Epoch 42/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2061 - val_loss: 0.1872\n",
      "Epoch 43/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1330 - val_loss: 0.2467\n",
      "Epoch 44/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1802 - val_loss: 0.1694\n",
      "Epoch 45/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1456 - val_loss: 0.2408\n",
      "Epoch 46/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1591 - val_loss: 0.2163\n",
      "Epoch 47/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1949 - val_loss: 0.1694\n",
      "Epoch 48/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1594 - val_loss: 0.1640\n",
      "Epoch 49/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1868 - val_loss: 0.2015\n",
      "Epoch 50/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1656 - val_loss: 0.1888\n",
      "Epoch 51/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1548 - val_loss: 0.1993\n",
      "Epoch 52/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1633 - val_loss: 0.1644\n",
      "Epoch 53/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1820 - val_loss: 0.4395\n",
      "Epoch 54/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2410 - val_loss: 0.4015\n",
      "Epoch 55/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2332 - val_loss: 0.1700\n",
      "Epoch 56/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2292 - val_loss: 0.2648\n",
      "Epoch 57/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2129 - val_loss: 0.1824\n",
      "Epoch 58/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1143 - val_loss: 0.1658\n",
      "Epoch 59/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.2083\n",
      "Epoch 60/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1955 - val_loss: 0.1862\n",
      "Epoch 61/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1405 - val_loss: 0.1991\n",
      "Epoch 62/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1341 - val_loss: 0.1667\n",
      "Epoch 63/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1378 - val_loss: 0.1884\n",
      "Epoch 64/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1773 - val_loss: 0.2412\n",
      "Epoch 65/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1752 - val_loss: 0.2905\n",
      "Epoch 66/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1721 - val_loss: 0.1984\n",
      "Epoch 67/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1234 - val_loss: 0.1575\n",
      "Epoch 68/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1642 - val_loss: 0.3246\n",
      "Epoch 69/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1987 - val_loss: 0.3133\n",
      "Epoch 70/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2548 - val_loss: 0.2224\n",
      "Epoch 71/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2296 - val_loss: 0.1570\n",
      "Epoch 72/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.1348\n",
      "Epoch 73/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1350 - val_loss: 0.1429\n",
      "Epoch 74/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1850 - val_loss: 0.2475\n",
      "Epoch 75/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1939 - val_loss: 0.2467\n",
      "Epoch 76/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2002 - val_loss: 0.1771\n",
      "Epoch 77/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1457 - val_loss: 0.1444\n",
      "Epoch 78/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1499 - val_loss: 0.1283\n",
      "Epoch 79/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1701 - val_loss: 0.2124\n",
      "Epoch 80/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1082 - val_loss: 0.1319\n",
      "Epoch 81/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2203 - val_loss: 0.3131\n",
      "Epoch 82/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2554 - val_loss: 0.1668\n",
      "Epoch 83/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1455 - val_loss: 0.1639\n",
      "Epoch 84/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1243 - val_loss: 0.1682\n",
      "Epoch 85/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1346 - val_loss: 0.2117\n",
      "Epoch 86/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1871 - val_loss: 0.1709\n",
      "Epoch 87/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1977 - val_loss: 0.2136\n",
      "Epoch 88/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1640 - val_loss: 0.1338\n",
      "Epoch 89/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1524 - val_loss: 0.1452\n",
      "Epoch 90/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1276 - val_loss: 0.1613\n",
      "Epoch 91/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1426 - val_loss: 0.2139\n",
      "Epoch 92/500\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.2169 - val_loss: 0.2142\n",
      "Epoch 93/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1398 - val_loss: 0.1590\n",
      "Epoch 94/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1506 - val_loss: 0.2081\n",
      "Epoch 95/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1203 - val_loss: 0.1367\n",
      "Epoch 96/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1278 - val_loss: 0.1385\n",
      "Epoch 97/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.1423\n",
      "Epoch 98/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1475 - val_loss: 0.1651\n",
      "Epoch 99/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1741 - val_loss: 0.3755\n",
      "Epoch 100/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1709 - val_loss: 0.1615\n",
      "Epoch 101/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1084 - val_loss: 0.1731\n",
      "Epoch 102/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1458 - val_loss: 0.3131\n",
      "Epoch 103/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2726 - val_loss: 0.2719\n",
      "Epoch 104/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1205 - val_loss: 0.1716\n",
      "Epoch 105/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1163 - val_loss: 0.1523\n",
      "Epoch 106/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1530 - val_loss: 0.1248\n",
      "Epoch 107/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1030 - val_loss: 0.1406\n",
      "Epoch 108/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2464 - val_loss: 0.1943\n",
      "Epoch 109/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1695 - val_loss: 0.1505\n",
      "Epoch 110/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1447 - val_loss: 0.1866\n",
      "Epoch 111/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2119 - val_loss: 0.1840\n",
      "Epoch 112/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1497 - val_loss: 0.1284\n",
      "Epoch 113/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1537 - val_loss: 0.1851\n",
      "Epoch 114/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1338 - val_loss: 0.1863\n",
      "Epoch 115/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1507 - val_loss: 0.2136\n",
      "Epoch 116/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1590 - val_loss: 0.1374\n",
      "Epoch 117/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1247 - val_loss: 0.2319\n",
      "Epoch 118/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1564 - val_loss: 0.1613\n",
      "Epoch 119/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1489 - val_loss: 0.1302\n",
      "Epoch 120/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1070 - val_loss: 0.2817\n",
      "Epoch 121/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1632 - val_loss: 0.1396\n",
      "Epoch 122/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1286 - val_loss: 0.1417\n",
      "Epoch 123/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1159 - val_loss: 0.2448\n",
      "Epoch 124/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.1072\n",
      "Epoch 125/500\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.1637 - val_loss: 0.1377\n",
      "Epoch 126/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1250 - val_loss: 0.2365\n",
      "Epoch 127/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1428 - val_loss: 0.1884\n",
      "Epoch 128/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1515 - val_loss: 0.1401\n",
      "Epoch 129/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2017 - val_loss: 0.1338\n",
      "Epoch 130/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1089 - val_loss: 0.1730\n",
      "Epoch 131/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1238 - val_loss: 0.2510\n",
      "Epoch 132/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1605 - val_loss: 0.2139\n",
      "Epoch 133/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2388 - val_loss: 0.1543\n",
      "Epoch 134/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1328 - val_loss: 0.1313\n",
      "Epoch 135/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.1131\n",
      "Epoch 136/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1134 - val_loss: 0.1429\n",
      "Epoch 137/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1727 - val_loss: 0.1741\n",
      "Epoch 138/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1691 - val_loss: 0.1386\n",
      "Epoch 139/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1444 - val_loss: 0.2895\n",
      "Epoch 140/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1632 - val_loss: 0.1280\n",
      "Epoch 141/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1371 - val_loss: 0.1206\n",
      "Epoch 142/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1261 - val_loss: 0.1403\n",
      "Epoch 143/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1314 - val_loss: 0.1444\n",
      "Epoch 144/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1488 - val_loss: 0.1633\n",
      "Epoch 145/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1222 - val_loss: 0.2524\n",
      "Epoch 146/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2449 - val_loss: 0.3687\n",
      "Epoch 147/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1484 - val_loss: 0.1766\n",
      "Epoch 148/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1521 - val_loss: 0.1760\n",
      "Epoch 149/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1037 - val_loss: 0.1394\n",
      "Epoch 150/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1128 - val_loss: 0.1721\n",
      "Epoch 151/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1233 - val_loss: 0.2187\n",
      "Epoch 152/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1493 - val_loss: 0.1533\n",
      "Epoch 153/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1390 - val_loss: 0.1519\n",
      "Epoch 154/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1205 - val_loss: 0.2259\n",
      "Epoch 155/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1838 - val_loss: 0.2856\n",
      "Epoch 156/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1728 - val_loss: 0.1479\n",
      "Epoch 157/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1560 - val_loss: 0.1444\n",
      "Epoch 158/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1528 - val_loss: 0.2980\n",
      "Epoch 159/500\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.1903 - val_loss: 0.1437\n",
      "Epoch 160/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1365 - val_loss: 0.3546\n",
      "Epoch 161/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1373 - val_loss: 0.1127\n",
      "Epoch 162/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.0956 - val_loss: 0.1190\n",
      "Epoch 163/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.1775 - val_loss: 0.1642\n",
      "Epoch 164/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1278 - val_loss: 0.1458\n",
      "Epoch 165/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1155 - val_loss: 0.1602\n",
      "Epoch 166/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1808 - val_loss: 0.1782\n",
      "Epoch 167/500\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.1103 - val_loss: 0.1383\n",
      "Epoch 168/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1210 - val_loss: 0.1890\n",
      "Epoch 169/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1219 - val_loss: 0.1462\n",
      "Epoch 170/500\n",
      "72/72 [==============================] - 0s 3ms/step - loss: 0.2005 - val_loss: 0.1439\n",
      "Epoch 171/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1221 - val_loss: 0.1476\n",
      "Epoch 172/500\n",
      "72/72 [==============================] - 0s 4ms/step - loss: 0.1372 - val_loss: 0.1520\n",
      "Epoch 173/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.2776 - val_loss: 0.1753\n",
      "Epoch 174/500\n",
      "72/72 [==============================] - 0s 2ms/step - loss: 0.1343 - val_loss: 0.1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1eb103510>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          validation_data=(x_valid,y_valid), \n",
    "          epochs=500, \n",
    "          batch_size=25,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(x_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.0, -6.0, 10.0, 25.0, 0.0, 9.0] => 28.322145 (expected 28.341298)\n",
      "[23.0, 0.0, 100.0, 25.0, 0.0, 9.0] => 12.754276 (expected 12.238082)\n",
      "[5.0, -1.0, 10.0, 12.5, 0.0, 9.0] => 23.247171 (expected 23.861305)\n",
      "[35.0, 0.0, 100.0, 25.0, 0.0, 15.0] => 9.890615 (expected 9.848776)\n",
      "[47.0, -4.0, 100.0, 12.5, 0.0, 9.0] => 10.203746 (expected 9.799840)\n",
      "[25.0, 0.0, 10.0, 25.0, 0.0, 3.0] => 20.377577 (expected 20.360340)\n",
      "[6.0, 3.0, 10.0, 25.0, 12.5, 9.0] => 23.592607 (expected 23.958640)\n",
      "[14.0, -1.0, 50.0, 25.0, 0.0, 9.0] => 19.875135 (expected 19.840868)\n",
      "[24.0, -7.0, 50.0, 25.0, 0.0, 3.0] => 17.906097 (expected 18.010393)\n",
      "[10.0, -5.0, 50.0, 25.0, 0.0, 9.0] => 23.469854 (expected 23.022427)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('%s => %f (expected %f)' % (x_test[i].tolist(), predictions[i], y_test[i] ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd7dbc09f62c6934dc245b76251cec5fd949cd1cb8bcb775af9208cac5a10da4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
